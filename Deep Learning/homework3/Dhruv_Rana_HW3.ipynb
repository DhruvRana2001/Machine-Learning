{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0) Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda for inference\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Using {DEVICE} for inference')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "#Optimizer\n",
    "LEARNING_RATE = 0.01\n",
    "WEIGHT_DECAY = 0.005\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "#Model\n",
    "NUM_INPUTS = 1*28*28 # grayscale (1-channel) 28*28 picture\n",
    "NUM_CLASSES = 10 # digits 0 to 9\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(), # Use tensors\n",
    "        transforms.Lambda(torch.flatten) # flatten the images\n",
    "        ])\n",
    "\n",
    "train_data = datasets.MNIST( \n",
    "    root=\"dataset\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform= transform\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"dataset\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform= transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_data, \n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         shuffle=False)\n",
    "\n",
    "CLASSES = train_data.classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Make Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTNet(nn.Module):\n",
    "\n",
    "    def __init__(self,num_inputs=NUM_INPUTS,num_classes=10):\n",
    "        super(MNISTNet, self).__init__()\n",
    "\n",
    "        self.fc1 =  nn.Sequential(\n",
    "            # num_input(784) -> 200\n",
    "            nn.Linear(in_features=num_inputs, out_features=200, bias=True),#Applies a linear transformation to the incoming data: y=xA^T+b\n",
    "            nn.ReLU(), #Applies the rectified linear unit function element-wise\n",
    "        )\n",
    "\n",
    "        self.fc2 =  nn.Sequential(\n",
    "            nn.Linear(in_features=200, out_features=50, bias=True),# 200 -> 50\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.fc3 =  nn.Sequential(\n",
    "            nn.Linear(in_features=50, out_features=num_classes, bias=True),# 50 -> 10\n",
    "        )\n",
    "\n",
    "        self.out =  nn.Sequential(\n",
    "            nn.Softmax(dim=1), # a Tensor of the same dimension and shape as the input with values in the range [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.out(x) # dont use softamx if using cross entorpy loss function of pytorch \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTNet(num_inputs=NUM_INPUTS, num_classes=NUM_CLASSES).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy (model, data_loader, device):\n",
    "    model = model.to(device)\n",
    "    model = model.eval() # put the model to evaultion mode\n",
    "    \n",
    "    num_correct_prediction = 0\n",
    "    num_total_labels = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(data_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            probabilities = model(inputs.to(DEVICE))\n",
    "            predicted_class = torch.argmax(probabilities, dim=1) # Class predicted by model\n",
    "            \n",
    "            num_total_labels += labels.size()[0]\n",
    "            num_correct_prediction += (predicted_class == labels).sum()\n",
    "\n",
    "    return num_correct_prediction/num_total_labels * 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Test w/o Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Num : 9\n",
      "Actual Num : 4\n",
      "\n",
      "Total Accuracy on test data : 9.630%\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "img  = np.reshape(images[4],(28,28))\n",
    "plt.imshow(img, cmap='Greys')\n",
    "plt.show()\n",
    "\n",
    "model = model.eval()\n",
    "\n",
    "with torch.no_grad(): # Save Performance when evaluting or prediciting\n",
    "    probabilities = model(images.to(DEVICE))\n",
    "    predicted_class = torch.argmax(probabilities,dim=1)\n",
    "\n",
    "print(\"Predicted Num : {:d}\".format(predicted_class[4]))\n",
    "print(\"Actual Num : {:d}\".format(labels[4]))\n",
    "print(\"\\nTotal Accuracy on test data : {:.3f}%\".format(compute_accuracy(model,test_loader,DEVICE)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model (model, data_loader, learning_rate, num_epochs,weight_decay,momentum,device):\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = weight_decay,momentum=momentum)\n",
    "    \n",
    "    best_weights = copy.deepcopy(model.state_dict())\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        print(\"EPOCH : {0}/{1}\".format(epoch+1,num_epochs))\n",
    "        print(\"-\"*30)\n",
    "        \n",
    "        # train first\n",
    "        model.train()\n",
    "        for batch_index, (inputs, labels) in enumerate(data_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)   \n",
    "             \n",
    "            probabilities = model(inputs)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            # Using NLL Loss instead of cross entorpy becuase it implements softmax, and our model uses softmax as the output layer\n",
    "            # Thus to avoid doble softmax I am using NLL loss\n",
    "            loss = nn.functional.nll_loss(torch.log(probabilities),labels)\n",
    "                \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (batch_index % 50 == 0) :\n",
    "                print(\"BATCH : {:3d}/{:3d} | LOSS : {:.3f} \".format(batch_index,len(data_loader),loss))\n",
    "        \n",
    "        # evalute\n",
    "        model.eval()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            accuracy = compute_accuracy(model,data_loader,DEVICE)\n",
    "            print(\"\\nTotal Accuracy On Training Data : {:.3f}%\".format(accuracy))\n",
    "        \n",
    "        # Save best weights\n",
    "        if (accuracy > best_accuracy):\n",
    "            best_accuracy = accuracy\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        print(\"Elapsed Time : {:.0f} min {:.0f} sec\\n\".format((time.time() - start_time)/60 , (time.time() - start_time)%60)) \n",
    "    \n",
    "    print(\"\\nTotal Time : {:.0f} min {:.0f} sec\".format((time.time() - start_time)/60 , (time.time() - start_time)%60))\n",
    "    \n",
    "    \n",
    "    model.load_state_dict(best_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 1/10\n",
      "------------------------------\n",
      "BATCH :   0/469 | LOSS : 2.310 \n",
      "BATCH :  50/469 | LOSS : 2.151 \n",
      "BATCH : 100/469 | LOSS : 1.290 \n",
      "BATCH : 150/469 | LOSS : 0.704 \n",
      "BATCH : 200/469 | LOSS : 0.506 \n",
      "BATCH : 250/469 | LOSS : 0.436 \n",
      "BATCH : 300/469 | LOSS : 0.342 \n",
      "BATCH : 350/469 | LOSS : 0.314 \n",
      "BATCH : 400/469 | LOSS : 0.392 \n",
      "BATCH : 450/469 | LOSS : 0.357 \n",
      "\n",
      "Total Accuracy On Training Data : 90.542%\n",
      "Elapsed Time : 0 min 11 sec\n",
      "\n",
      "EPOCH : 2/10\n",
      "------------------------------\n",
      "BATCH :   0/469 | LOSS : 0.396 \n",
      "BATCH :  50/469 | LOSS : 0.485 \n",
      "BATCH : 100/469 | LOSS : 0.395 \n",
      "BATCH : 150/469 | LOSS : 0.469 \n",
      "BATCH : 200/469 | LOSS : 0.375 \n",
      "BATCH : 250/469 | LOSS : 0.264 \n",
      "BATCH : 300/469 | LOSS : 0.313 \n",
      "BATCH : 350/469 | LOSS : 0.282 \n",
      "BATCH : 400/469 | LOSS : 0.305 \n",
      "BATCH : 450/469 | LOSS : 0.345 \n",
      "\n",
      "Total Accuracy On Training Data : 92.158%\n",
      "Elapsed Time : 0 min 22 sec\n",
      "\n",
      "EPOCH : 3/10\n",
      "------------------------------\n",
      "BATCH :   0/469 | LOSS : 0.244 \n",
      "BATCH :  50/469 | LOSS : 0.248 \n",
      "BATCH : 100/469 | LOSS : 0.246 \n",
      "BATCH : 150/469 | LOSS : 0.314 \n",
      "BATCH : 200/469 | LOSS : 0.271 \n",
      "BATCH : 250/469 | LOSS : 0.366 \n",
      "BATCH : 300/469 | LOSS : 0.336 \n",
      "BATCH : 350/469 | LOSS : 0.255 \n",
      "BATCH : 400/469 | LOSS : 0.214 \n",
      "BATCH : 450/469 | LOSS : 0.324 \n",
      "\n",
      "Total Accuracy On Training Data : 93.735%\n",
      "Elapsed Time : 1 min 33 sec\n",
      "\n",
      "EPOCH : 4/10\n",
      "------------------------------\n",
      "BATCH :   0/469 | LOSS : 0.335 \n",
      "BATCH :  50/469 | LOSS : 0.210 \n",
      "BATCH : 100/469 | LOSS : 0.199 \n",
      "BATCH : 150/469 | LOSS : 0.238 \n",
      "BATCH : 200/469 | LOSS : 0.182 \n",
      "BATCH : 250/469 | LOSS : 0.318 \n",
      "BATCH : 300/469 | LOSS : 0.219 \n",
      "BATCH : 350/469 | LOSS : 0.213 \n",
      "BATCH : 400/469 | LOSS : 0.281 \n",
      "BATCH : 450/469 | LOSS : 0.210 \n",
      "\n",
      "Total Accuracy On Training Data : 94.388%\n",
      "Elapsed Time : 1 min 44 sec\n",
      "\n",
      "EPOCH : 5/10\n",
      "------------------------------\n",
      "BATCH :   0/469 | LOSS : 0.224 \n",
      "BATCH :  50/469 | LOSS : 0.184 \n",
      "BATCH : 100/469 | LOSS : 0.126 \n",
      "BATCH : 150/469 | LOSS : 0.294 \n",
      "BATCH : 200/469 | LOSS : 0.111 \n",
      "BATCH : 250/469 | LOSS : 0.284 \n",
      "BATCH : 300/469 | LOSS : 0.109 \n",
      "BATCH : 350/469 | LOSS : 0.187 \n",
      "BATCH : 400/469 | LOSS : 0.138 \n",
      "BATCH : 450/469 | LOSS : 0.190 \n",
      "\n",
      "Total Accuracy On Training Data : 95.077%\n",
      "Elapsed Time : 1 min 55 sec\n",
      "\n",
      "EPOCH : 6/10\n",
      "------------------------------\n",
      "BATCH :   0/469 | LOSS : 0.246 \n",
      "BATCH :  50/469 | LOSS : 0.189 \n",
      "BATCH : 100/469 | LOSS : 0.169 \n",
      "BATCH : 150/469 | LOSS : 0.276 \n",
      "BATCH : 200/469 | LOSS : 0.194 \n",
      "BATCH : 250/469 | LOSS : 0.120 \n",
      "BATCH : 300/469 | LOSS : 0.229 \n",
      "BATCH : 350/469 | LOSS : 0.108 \n",
      "BATCH : 400/469 | LOSS : 0.181 \n",
      "BATCH : 450/469 | LOSS : 0.156 \n",
      "\n",
      "Total Accuracy On Training Data : 95.528%\n",
      "Elapsed Time : 1 min 6 sec\n",
      "\n",
      "EPOCH : 7/10\n",
      "------------------------------\n",
      "BATCH :   0/469 | LOSS : 0.226 \n",
      "BATCH :  50/469 | LOSS : 0.156 \n",
      "BATCH : 100/469 | LOSS : 0.203 \n",
      "BATCH : 150/469 | LOSS : 0.148 \n",
      "BATCH : 200/469 | LOSS : 0.264 \n",
      "BATCH : 250/469 | LOSS : 0.107 \n",
      "BATCH : 300/469 | LOSS : 0.196 \n",
      "BATCH : 350/469 | LOSS : 0.132 \n",
      "BATCH : 400/469 | LOSS : 0.176 \n",
      "BATCH : 450/469 | LOSS : 0.306 \n",
      "\n",
      "Total Accuracy On Training Data : 96.028%\n",
      "Elapsed Time : 1 min 17 sec\n",
      "\n",
      "EPOCH : 8/10\n",
      "------------------------------\n",
      "BATCH :   0/469 | LOSS : 0.118 \n",
      "BATCH :  50/469 | LOSS : 0.149 \n",
      "BATCH : 100/469 | LOSS : 0.150 \n",
      "BATCH : 150/469 | LOSS : 0.185 \n",
      "BATCH : 200/469 | LOSS : 0.234 \n",
      "BATCH : 250/469 | LOSS : 0.099 \n",
      "BATCH : 300/469 | LOSS : 0.126 \n",
      "BATCH : 350/469 | LOSS : 0.088 \n",
      "BATCH : 400/469 | LOSS : 0.132 \n",
      "BATCH : 450/469 | LOSS : 0.157 \n",
      "\n",
      "Total Accuracy On Training Data : 96.003%\n",
      "Elapsed Time : 1 min 28 sec\n",
      "\n",
      "EPOCH : 9/10\n",
      "------------------------------\n",
      "BATCH :   0/469 | LOSS : 0.164 \n",
      "BATCH :  50/469 | LOSS : 0.148 \n",
      "BATCH : 100/469 | LOSS : 0.134 \n",
      "BATCH : 150/469 | LOSS : 0.136 \n",
      "BATCH : 200/469 | LOSS : 0.176 \n",
      "BATCH : 250/469 | LOSS : 0.111 \n",
      "BATCH : 300/469 | LOSS : 0.126 \n",
      "BATCH : 350/469 | LOSS : 0.217 \n",
      "BATCH : 400/469 | LOSS : 0.087 \n",
      "BATCH : 450/469 | LOSS : 0.160 \n",
      "\n",
      "Total Accuracy On Training Data : 96.207%\n",
      "Elapsed Time : 2 min 39 sec\n",
      "\n",
      "EPOCH : 10/10\n",
      "------------------------------\n",
      "BATCH :   0/469 | LOSS : 0.141 \n",
      "BATCH :  50/469 | LOSS : 0.115 \n",
      "BATCH : 100/469 | LOSS : 0.114 \n",
      "BATCH : 150/469 | LOSS : 0.146 \n",
      "BATCH : 200/469 | LOSS : 0.167 \n",
      "BATCH : 250/469 | LOSS : 0.124 \n",
      "BATCH : 300/469 | LOSS : 0.122 \n",
      "BATCH : 350/469 | LOSS : 0.160 \n",
      "BATCH : 400/469 | LOSS : 0.139 \n",
      "BATCH : 450/469 | LOSS : 0.122 \n",
      "\n",
      "Total Accuracy On Training Data : 96.378%\n",
      "Elapsed Time : 2 min 50 sec\n",
      "\n",
      "\n",
      "Total Time : 2 min 50 sec\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model,train_loader,LEARNING_RATE,NUM_EPOCHS,WEIGHT_DECAY,MOMENTUM,DEVICE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Test w/ Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Num : 6\n",
      "Actual Num : 6\n",
      "\n",
      "Total Accuracy on test data : 96.080%\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "img  = np.reshape(images[4],(28,28))\n",
    "plt.imshow(img, cmap='Greys')\n",
    "plt.show()\n",
    "\n",
    "model = model.eval()\n",
    "\n",
    "with torch.no_grad(): # Save Performance when evaluting or prediciting\n",
    "    probabilities = model(images.to(DEVICE))\n",
    "    predicted_class = torch.argmax(probabilities,dim=1)\n",
    "\n",
    "print(\"Predicted Num : {:d}\".format(predicted_class[4]))\n",
    "print(\"Actual Num : {:d}\".format(labels[4]))\n",
    "print(\"\\nTotal Accuracy on test data : {:.3f}%\".format(compute_accuracy(model,test_loader,DEVICE)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ComputerVision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2531915ab5b6d7f6e073a1b4ef06ed0b2b780c8145dd924165dc427f5e6c9cf0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
